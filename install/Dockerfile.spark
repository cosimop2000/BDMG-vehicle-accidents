FROM df-benchmarks

RUN apt-get update && \
    apt-get install -y openjdk-11-jdk && \
    wget https://archive.apache.org/dist/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz && \
    tar xvf spark-3.2.1-bin-hadoop3.2.tgz && \
    rm spark-3.2.1-bin-hadoop3.2.tgz && \
    mv spark-3.2.1-bin-hadoop3.2 /opt/spark && \
    ln -s /opt/spark /spark


ENV JAVA_HOME /usr/lib/jvm/java-11-openjdk-amd64

ENV PATH $JAVA_HOME/bin:$PATH

ENV PYSPARK_PYTHON=python3.9
ENV PATH=$PATH:/spark/bin

RUN pip install --upgrade pip
# Install Pyspark and its dependencies 
RUN pip install pyspark
