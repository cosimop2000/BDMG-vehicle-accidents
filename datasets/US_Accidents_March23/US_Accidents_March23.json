{
    "Input": [
        {
            "method": "load_dataset",
            "input_pandas": {
                "sep": ","
            },

            "input_vaex": {
            },
            "input_polars":{

            },
            "input_datatable":{

            },
            "input_spark":{
                "sep": ",",
                "format": "csv"
            },
            "input_dask":{

            },
            "input_pyspark_pandas":{

            },
            "input_modin_ray":{
                

            }
        },
        {
            "method": "force_execution",
            "input": {}
        }
    ],

    "EDA": [
        {
            "method": "get_columns",
            "input":{}
        },
        
        {
            "method": "get_stats",
            "input": {}
        },
        {
            "method": "perc_null_values",
            "input":{}
        },
        {
            "method":"query",
            "input_pandas":{
                "query":"(Start_Lat == End_Lat) & (Start_Lng == End_Lng)"
            },
            "input_vaex":{
                "query":"(Start_Lat == End_Lat) & (Start_Lng == End_Lng)"
            },
            "input_spark":{
                "query":"(fn.col('Start_Lat') == fn.col('End_Lat')) & (fn.col('Start_Lng') == fn.col('End_Lng'))"
            }

        },
        {
            "method":"check_missing_values",
            "input_pandas":{
                "col1": "End_Lat",
                "col2": "End_Lng"
            },
            "input_vaex":{
                "col1": "End_Lat",
                "col2": "End_Lng"
            },
            "input_spark":{
                "col1": "End_Lat",
                "col2": "End_Lng"
            }
        },
        {
            "method":"is_unique",
            "input_pandas":{
                "column":"ID"
            },
            "input_vaex":{
                "column":"ID"
            },
            "input_spark":{
                "column":"ID"
            }
        },
        {
            "method":"is_unique",
            "input_pandas":{
                "column":"Description"
            },
            "input_vaex":{
                "column":"Description"
            },
            "input_spark":{
                "column":"Description"
            }
        },
        {
            "method":"is_unique",
            "input_pandas":{
                "column":"Wind_Direction"
            },
            "input_vaex":{
                "column":"Wind_Direction"
            },
            "input_spark":{
                "column":"Wind_Direction"
            }
        },
        {
            "method":"locate_null_values",
            "input_pandas":{
                "column":"Airport_Code"
            },
            "input_vaex":{
                "column":"Airport_Code"
            },
            "input_spark":{
                "column":"all"
            }
        },
        {
            "method":"query",
            "input_pandas":{
                "query":"`Precipitation(in)` == 0"
            },
            "input_vaex":{
                "query":"`Precipitation(in)` == 0"
            },
            "input_spark":{
                "query":"fn.col('Precipitation(in)') == 0"
            }

        },
        {
            "method":"look_for_cases",
            "input_pandas":{
                "col1":"Humidity(%)",
                "col2":"Precipitation(in)",
                "col3":"Humidity(%)",
                "col4":"Precipitation(in)"
            },
            "input_vaex":{
                "col1":"Humidity(%)",
                "col2":"Precipitation(in)",
                "col3":"Humidity(%)",
                "col4":"Precipitation(in)"     
            },
            "input_spark":{
                "col1":"Humidity(%)",
                "col2":"Precipitation(in)",
                "col3":"Humidity(%)",
                "col4":"Precipitation(in)"     
            }
        },
        {
            "method":"look_for_cases",
            "input_pandas":{
                "col1":"Wind_Speed(mph)",
                "col2":"Wind_Chill(F)",
                "col3":"Wind_Speed(mph)",
                "col4":"Wind_Chill(F)"
            },
            "input_vaex":{
                "col1":"Wind_Speed(mph)",
                "col2":"Wind_Chill(F)",
                "col3":"Wind_Speed(mph)",
                "col4":"Wind_Chill(F)"    
            },
            "input_spark":{
                "col1":"Wind_Speed(mph)",
                "col2":"Wind_Chill(F)",
                "col3":"Wind_Speed(mph)",
                "col4":"Wind_Chill(F)"    
            }
        },
        {
            "method":"sample_rows",
            "input_pandas":{
                "frac": true,
                "num": 1
            },
            "input_vaex":{
                "frac": true,
                "num": 1    
            },
            "input_spark":{
                "frac": true,
                "num": 1    
            }
        },
        {
            "method":"sort",
            "input_pandas":{
                "columns":["Weather_Condition"]
            },
            "input_vaex":{
                "columns":["Weather_Condition"]
            },
            "input_spark":{
                "columns":["Weather_Condition"]
            }
        },
        {
            "method":"plot_geo",
            "input_pandas":{
                "frame": "gdfs_sample",
                "i": "Severity",
                "req_compile":[
                    "frame"
                ],
                "extra_commands":[
                    "import geopandas",
                    "import geoplot as gplt",
                    "import geoplot.crs as gcrs",
                    "import matplotlib.pyplot as plt",
                    "import pandas as pd",
                    "accident_data = pd.read_csv(r'datasets/test/sample.csv')",
                    "severity_locations = accident_data[['Temperature(F)','Wind_Chill(F)','Severity','Start_Lng','Start_Lat']]",
                    "gdf_severity = geopandas.GeoDataFrame(severity_locations, geometry=geopandas.points_from_xy(severity_locations.Start_Lng, severity_locations.Start_Lat))",
                    "gdfs_sample = gdf_severity.sample(int(len(gdf_severity)/10))",
                    "print(gdfs_sample)"

                ]
            },
            "input_vaex":{
                "frame": "gdfs_sample",
                "i": 2,
                "req_compile":[
                    "frame"
                ],
                "extra_commands":[
                    "import geopandas",
                    "import geoplot as gplt",
                    "import geoplot.crs as gcrs",
                    "import matplotlib.pyplot as plt",
                    "import pandas as pd",
                    "import numpy as np",
                    "import vaex as vx",
                    "accident_data = vx.read_csv(r'datasets/test/sample.csv')",
                    "severity_locations = accident_data[['Temperature(F)','Wind_Chill(F)','Severity','Start_Lng','Start_Lat']]",
                    "start_lng = accident_data['Start_Lng'].to_numpy()",
                    "start_lat = accident_data['Start_Lat'].to_numpy()",
                    "gdf_severity = geopandas.GeoDataFrame(severity_locations, geometry=geopandas.points_from_xy(start_lng, start_lat))",
                    "gdfs_sample = gdf_severity.sample(int(len(gdf_severity)/10))",
                    "print(gdfs_sample)"

                ]
            },
            "input_spark":{
                "frame": "gdfs_sample",
                "i":  "Severity",
                "req_compile":[
                    "frame"
                ],
                "extra_commands":[
                    "import geopandas",
                    "import geoplot as gplt",
                    "import geoplot.crs as gcrs",
                    "import pandas as pd",
                    "import numpy as np",
                    "from pyspark.sql import DataFrame, SparkSession",
                    "from pyspark.sql.functions import col, expr, lit",
                    "import matplotlib.pyplot as plt",
                    "import pyspark.sql.functions as fn",
                    "accident_data = pd.read_csv(r'datasets/US_Accidents_March23/test.csv')",
                    "severity_locations = accident_data[['Temperature(F)','Wind_Chill(F)','Severity','Start_Lng','Start_Lat']]",
                    "gdf_severity = geopandas.GeoDataFrame(severity_locations, geometry=geopandas.points_from_xy(severity_locations.Start_Lng, severity_locations.Start_Lat))",
                    "l = len(gdf_severity)",
                    "gdfs_sample = gdf_severity.sample(int(l/10))",
                    "print(gdfs_sample)"

                ]
            },
            "input_spark2":{
                "frame": "gdfs_sample",
                "i": "fn.col('Severity')",
                "req_compile":[
                    "frame"
                ],
                "extra_commands":[
                    "import pandas as pd",
                    "import numpy as np",
                    "from pyspark.sql import DataFrame, SparkSession",
                    "from pyspark.sql.functions import col, expr, lit",
                    "import matplotlib.pyplot as plt",
                    "import pyspark.sql.functions as fn",
                    "spark = SparkSession.builder.appName('AccidentData').getOrCreate()",
                    "accident_data = spark.read.csv(r'datasets/US_Accidents_March23/test.csv', header=True, inferSchema=True)",
                    "severity_locations = accident_data.select('Temperature(F)','Wind_Chill(F)','Severity','Start_Lng','Start_Lat')",
                    "severity_locations_with_geometry = severity_locations.withColumn('geometry',lit(None).cast('string'))",
                    "crs = 'EPSG:4326'",
                    "gdf_severity = severity_locations_with_geometry.select('Temperature(F)','Wind_Chill(F)','Severity','Start_Lng','Start_Lat',col('geometry').alias('geometry') )",
                    "gdfs_sample = gdf_severity.sample(withReplacement=False, fraction=0.1, seed=42)",
                    "print(gdfs_sample)"

                ]
            }
        },
        {
            "method":"plot_geo",
            "input_pandas":{
                "frame": "gdfs_sample",
                "i": "Temperature(F)",
                "req_compile":[
                    "frame"
                ],
                "extra_commands":[
                    "import geopandas",
                    "import geoplot as gplt",
                    "import geoplot.crs as gcrs",
                    "import matplotlib.pyplot as plt",
                    "import pandas as pd",
                    "accident_data = pd.read_csv(r'datasets/test/sample.csv')",
                    "severity_locations = accident_data[['Temperature(F)','Wind_Chill(F)','Severity','Start_Lng','Start_Lat']]",
                    "gdf_severity = geopandas.GeoDataFrame(severity_locations, geometry=geopandas.points_from_xy(severity_locations.Start_Lng, severity_locations.Start_Lat))",
                    "gdfs_sample = gdf_severity.sample(int(len(gdf_severity)/10))",
                    "print(gdfs_sample)"

                ]
            },
            "input_vaex":{
                "frame": "gdfs_sample",
                "i": 0,
                "req_compile":[
                    "frame"
                ],
                "extra_commands":[
                    "import geopandas",
                    "import geoplot as gplt",
                    "import geoplot.crs as gcrs",
                    "import matplotlib.pyplot as plt",
                    "import pandas as pd",
                    "import numpy as np",
                    "import vaex as vx",
                    "accident_data = vx.read_csv(r'datasets/test/sample.csv')",
                    "severity_locations = accident_data[['Temperature(F)','Wind_Chill(F)','Severity','Start_Lng','Start_Lat']]",
                    "start_lng = accident_data['Start_Lng'].to_numpy()",
                    "start_lat = accident_data['Start_Lat'].to_numpy()",
                    "gdf_severity = geopandas.GeoDataFrame(severity_locations, geometry=geopandas.points_from_xy(start_lng, start_lat))",
                    "gdfs_sample = gdf_severity.sample(int(len(gdf_severity)/10))",
                    "print(gdfs_sample)"

                ]
            },
            "input_spark":{
                "frame": "gdfs_sample",
                "i":  "Temperature(F)",
                "req_compile":[
                    "frame"
                ],
                "extra_commands":[
                    "import geopandas",
                    "import geoplot as gplt",
                    "import geoplot.crs as gcrs",
                    "import pandas as pd",
                    "import numpy as np",
                    "from pyspark.sql import DataFrame, SparkSession",
                    "from pyspark.sql.functions import col, expr, lit",
                    "import matplotlib.pyplot as plt",
                    "import pyspark.sql.functions as fn",
                    "accident_data = pd.read_csv(r'datasets/US_Accidents_March23/test.csv')",
                    "severity_locations = accident_data[['Temperature(F)','Wind_Chill(F)','Severity','Start_Lng','Start_Lat']]",
                    "gdf_severity = geopandas.GeoDataFrame(severity_locations, geometry=geopandas.points_from_xy(severity_locations.Start_Lng, severity_locations.Start_Lat))",
                    "l = len(gdf_severity)",
                    "gdfs_sample = gdf_severity.sample(int(l/10))",
                    "print(gdfs_sample)"

                ]
            }
        },
        {
            "method":"plot_geo",
            "input_pandas":{
                "frame": "gdfs_sample",
                "i": "Wind_Chill(F)",
                "req_compile":[
                    "frame"
                ],
                "extra_commands":[
                    "import geopandas",
                    "import geoplot as gplt",
                    "import geoplot.crs as gcrs",
                    "import matplotlib.pyplot as plt",
                    "import pandas as pd",
                    "accident_data = pd.read_csv(r'datasets/test/sample.csv')",
                    "severity_locations = accident_data[['Temperature(F)','Wind_Chill(F)','Severity','Start_Lng','Start_Lat']]",
                    "gdf_severity = geopandas.GeoDataFrame(severity_locations, geometry=geopandas.points_from_xy(severity_locations.Start_Lng, severity_locations.Start_Lat))",
                    "gdfs_sample = gdf_severity.sample(int(len(gdf_severity)/10))",
                    "print(gdfs_sample)"

                ]
            },
            "input_vaex":{
                "frame": "gdfs_sample",
                "i": 1,
                "req_compile":[
                    "frame"
                ],
                "extra_commands":[
                    "import geopandas",
                    "import geoplot as gplt",
                    "import geoplot.crs as gcrs",
                    "import matplotlib.pyplot as plt",
                    "import pandas as pd",
                    "import numpy as np",
                    "import vaex as vx",
                    "accident_data = vx.read_csv(r'datasets/test/sample.csv')",
                    "severity_locations = accident_data[['Temperature(F)','Wind_Chill(F)','Severity','Start_Lng','Start_Lat']]",
                    "start_lng = accident_data['Start_Lng'].to_numpy()",
                    "start_lat = accident_data['Start_Lat'].to_numpy()",
                    "gdf_severity = geopandas.GeoDataFrame(severity_locations, geometry=geopandas.points_from_xy(start_lng, start_lat))",
                    "gdfs_sample = gdf_severity.sample(int(len(gdf_severity)/10))",
                    "print(gdfs_sample)"

                ]
            },
            "input_spark":{
                "frame": "gdfs_sample",
                "i": "Wind_Chill(F)",
                "req_compile":[
                    "frame"
                ],
                "extra_commands":[
                    "import geopandas",
                    "import geoplot as gplt",
                    "import geoplot.crs as gcrs",
                    "import pandas as pd",
                    "import numpy as np",
                    "from pyspark.sql import DataFrame, SparkSession",
                    "from pyspark.sql.functions import col, expr, lit",
                    "import matplotlib.pyplot as plt",
                    "import pyspark.sql.functions as fn",
                    "accident_data = pd.read_csv(r'datasets/US_Accidents_March23/test.csv')",
                    "severity_locations = accident_data[['Temperature(F)','Wind_Chill(F)','Severity','Start_Lng','Start_Lat']]",
                    "gdf_severity = geopandas.GeoDataFrame(severity_locations, geometry=geopandas.points_from_xy(severity_locations.Start_Lng, severity_locations.Start_Lat))",
                    "l = len(gdf_severity)",
                    "gdfs_sample = gdf_severity.sample(int(l/10))",
                    "print(gdfs_sample)"

                ]
            }
        },
        {
            "method": "force_execution",
            "input": {}
        }



    ],

    "data_transformation": [
        {
            "method":"change_date_time_format",
            "input_pandas":{
                "column":"Start_Time",
                "format":"%Y-%m-%d %H:%M:%S"
            },
            "input_vaex":{
                "column":"Start_Time",
                "format":"%Y-%m-%d %H:%M:%S"    
            },
            "input_spark":{
                "column":"Start_Time",
                "format":"yyyy-MM-dd HH:mm:ss"    
            }
        },
        {
            "method":"change_date_time_format",
            "input_pandas":{
                "column":"End_Time",
                "format":"%Y-%m-%d %H:%M:%S"
            },
            "input_vaex":{
                "column":"End_Time",
                "format":"%Y-%m-%d %H:%M:%S"    
            },
            "input_spark":{
                "column":"End_Time",
                "format":"yyyy-MM-dd HH:mm:ss"
            }
        },
        {
            "method":"change_date_time_format",
            "input_pandas":{
                "column":"Weather_Timestamp",
                "format":"%Y-%m-%d %H:%M:%S"
            },
            "input_vaex":{
                "column":"Weather_Timestamp",
                "format":"%Y-%m-%d %H:%M:%S"    
            },
            "input_spark":{
                "column":"Weather_Timestamp",
                "format":"yyyy-MM-dd HH:mm:ss"
            }
        },
        {
            "method":"split",
            "input_pandas":{
                "column":"Weather_Timestamp",
                "sep": " ",
                "splits": 2,
                "col_names": ["day", "hour"]

            },
            "input_vaex":{
                "column":"Weather_Timestamp",
                "sep": " ",
                "splits": 2,
                "col_names": ["day", "hour"]

            },
            "input_spark":{
                "column":"Weather_Timestamp",
                "sep": " ",
                "splits": 2,
                "col_names": ["day", "hour"]

            }
        },
        {
            "method":"delete_columns",
            "input_pandas":{
                "columns":["ID","Start_Time","End_Time", "Weather_Timestamp"]
            },
            "input_vaex":{
                "columns":["ID","Start_Time","End_Time", "Weather_Timestamp"]
            },
            "input_spark":{
                "columns":["ID","Start_Time","End_Time", "Weather_Timestamp"]
            }
        },
        {
            "method":"calc_column",
            "input_pandas":{
                "col_name":"abs_end_lng_change",
                "columns":["End_Lng"],
                "f":"lambda x: abs(x)"
            },
            "input_vaex":{
                "col_name":"abs_end_lng_change",
                "columns":["End_Lng"],
                "f":"lambda x: abs(x)"    
            },
            "input_spark":{
                "col_name":"abs_end_lng_change",
                "columns":["End_Lng"],
                "f":"lambda x: abs(x)"
            }
        },
        {
            "method":"calc_column",
            "input_pandas":{
                "col_name":"abs_end_lat_change",
                "columns":["End_Lat"],
                "f":"lambda x: abs(x)"
            },
            "input_vaex":{
                "col_name":"abs_end_lat_change",
                "columns":["End_Lat"],
                "f":"lambda x: abs(x)"    
            },
            "input_spark":{
                "col_name":"abs_end_lat_change",
                "columns":["End_Lat"],
                "f":"lambda x: abs(x)"
            }
        },
        {
            "method":"simple_imputer",
            "input_pandas":{
                "columns":["Temperature(F)","Wind_Chill(F)","Humidity(%)","Pressure(in)","Visibility(mi)","Wind_Speed(mph)","Precipitation(in)"]
            },
            "input_vaex":{
                "columns":["Temperature(F)","Wind_Chill(F)","Humidity(%)","Pressure(in)","Visibility(mi)","Wind_Speed(mph)","Precipitation(in)"]    
            },
            "input_spark":{
                "columns":["Temperature(F)","Wind_Chill(F)","Humidity(%)","Pressure(in)","Visibility(mi)","Wind_Speed(mph)","Precipitation(in)"]
            }
        },
        {
            "method":"pca",
            "input_pandas":{
                "data_pca":"data_pca",
                "n_dim": 3,
                "req_compile":[
                    "data_pca"
                ],
                "extra_commands":[
                    "import pandas as pd",
                    "accident_data = pd.read_csv(r'datasets/test/sample.csv')",
                    "numerical = ['Start_Lat', 'Start_Lng', 'End_Lat', 'End_Lng', 'Distance(mi)', 'Temperature(F)', 'Wind_Chill(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)','Wind_Speed(mph)', 'Precipitation(in)']",
                    "accident_sample = accident_data[numerical].sample(int(len(accident_data)/100))",
                    "data_pca = (accident_sample - accident_sample.mean(axis=0)) / accident_sample.std(axis=0)"
                ]
            },
            "input_vaex":{
                "data_pca":"data_pca",
                "req_compile":[
                    "data_pca"
                ],
                "extra_commands":[
                    "import vaex as vx",
                    "accident_data = vx.read_csv(r'datasets/test/sample.csv')",
                    "numerical = ['Start_Lat', 'Start_Lng', 'End_Lat', 'End_Lng', 'Distance(mi)', 'Temperature(F)', 'Wind_Chill(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)','Wind_Speed(mph)', 'Precipitation(in)']",
                    "accident_sample = accident_data[numerical].sample(int(len(accident_data)/100))",
                    "data_pca = accident_sample.dropna()"
                    
                ]
            }
        },
        {
            "method": "force_execution",
            "input": {}    
        }

    ],

    "data_cleaning": [
        {
            "method":"replace",
            "input_pandas":{
                "columns":["Weather_Condition"],
                "to_replace": {
                    "Thunder": "Thunderstorm",
                    "T-Storm": "Thunderstorm",
                    "T-Storm / Windy": "Thunderstorm / Windy",
                    "Thunder / Windy": "Thunderstorm / Windy",
                    "Heavy Rain Shower": "Heavy Rain",
                    "Heavy Rain Showers": "Heavy Rain",
                    "Light Rain Shower": "Light Rain",
                    "Light Rain Showers": "Light Rain",
                    "Rain Shower": "Rain",
                    "Rain Showers": "Rain"
                }
            },
            "input_vaex":{
                "columns":["Weather_Condition"],
                "to_replace": {
                    "Thunder": "Thunderstorm",
                    "T-Storm": "Thunderstorm",
                    "T-Storm / Windy": "Thunderstorm / Windy",
                    "Thunder / Windy": "Thunderstorm / Windy",
                    "Heavy Rain Shower": "Heavy Rain",
                    "Heavy Rain Showers": "Heavy Rain",
                    "Light Rain Shower": "Light Rain",
                    "Light Rain Showers": "Light Rain",
                    "Rain Shower": "Rain",
                    "Rain Showers": "Rain"
                }
            },
            "input_spark":{
                "columns":["Weather_Condition"],
                "to_replace": {
                    "Thunder": "Thunderstorm",
                    "T-Storm": "Thunderstorm",
                    "T-Storm / Windy": "Thunderstorm / Windy",
                    "Thunder / Windy": "Thunderstorm / Windy",
                    "Heavy Rain Shower": "Heavy Rain",
                    "Heavy Rain Showers": "Heavy Rain",
                    "Light Rain Shower": "Light Rain",
                    "Light Rain Showers": "Light Rain",
                    "Rain Shower": "Rain",
                    "Rain Showers": "Rain"
                }
            }
        },
        {
            "method":"replace",
            "input_pandas":{
                "columns":["Wind_Direction"],
                "to_replace": {
                    "West": "W",
                    "Variable": "VAR",
                    "South": "S",
                    "Calm": "CALM",
                    "East": "E",
                    "North": "N"
                }
            },
            "input_vaex":{
                "columns":["Wind_Direction"],
                "to_replace": {
                    "West": "W",
                    "Variable": "VAR",
                    "South": "S",
                    "Calm": "CALM",
                    "East": "E",
                    "North": "N"
                }
            },
            "input_spark":{
                "columns":["Wind_Direction"],
                "to_replace": {
                    "West": "W",
                    "Variable": "VAR",
                    "South": "S",
                    "Calm": "CALM",
                    "East": "E",
                    "North": "N"
                }
            }
        },
        {
            "method":"fill_nan",
            "input_pandas":{
                "value":"KBTR",
                "columns":["Airport_Code"]
            },
            "input_vaex":{
                "value":"KBTR",
                "columns":["Airport_Code"]    
            },
            "input_spark":{
                "value":"KBTR",
                "columns":["Airport_Code"]
            }
        },
        {
            "method":"fill_nan",
            "input_pandas":{
                "value":"CALM",
                "columns":["Wind_Direction"]
            },
            "input_vaex":{
                "value":"CALM",
                "columns":["Wind_Direction"]    
            },
            "input_spark":{
                "value":"CALM",
                "columns":["Wind_Direction"]
            }
        },
        {
            "method":"fill_nan",
            "input_pandas":{
                "value":"Day",
                "columns":["Sunrise_Sunset"]
            },
            "input_vaex":{
                "value":"CALM",
                "columns":["Sunrise_Sunset"]    
            },
            "input_spark":{
                "value":"Day",
                "columns":["Sunrise_Sunset"]
            }
        },
        {
            "method":"delete_empty_rows",
            "input_pandas":{
                "columns":"all"
            },
            "input_vaex":{
                "columns":"all"
            },
            "input_spark":{
                "columns":"all"
            }
        },
        {
            "method":"split",
            "input_pandas":{
                "column":"Zipcode",
                "sep": "-",
                "splits": 2,
                "col_names": ["Zipcode_ok", "Zipcode_not_ok"]

            },
            "input_vaex":{
                "column":"Zipcode",
                "sep": "-",
                "splits": 2,
                "col_names": ["Zipcode_ok", "Zipcode_not_ok"]
            },
            "input_spark":{
                "column":"Zipcode",
                "sep": "-",
                "splits": 2,
                "col_names": ["Zipcode_ok", "Zipcode_not_ok"]

            }
        },
        {
            "method": "force_execution",
            "input": {}
        
        }

    ],

    "output": [



    ]


}